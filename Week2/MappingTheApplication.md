# Mapping the Application

One of the first processes with hacking any web application is mapping it. The idea behind this is the ability to find its strengths and weaknesses. This allows for possible enumeration where possible thanks to finding the inner workings within the application.

## Directory

**[Web Spidering](#Web-Spidering)**<br>
**[User-Directed Spiders](#User-Directed-Spiders)**<br>
**[Discovering Hidden Content](#Discovering-Hidden-Content)**<br>
**[Discovering Hidden Parameters](#Discovering-Hidden-Parameters)**<br>
**[Analyzing the Application](#Analyzing-the-Application)**<br>
**[Identifying Entry Points for User Input](#Identifying-Entry-Points-for-User-Input)**<br>
**[Identifying Server-Side Technology](#Identifying-Server-Side-Technology)**<br>
**[Identifying Server-Side Functionality](#Identifying-Server-Side-Functionality)**<br>
**[Mapping the Attack Surface](#Mapping-the-Attack-Surface)**

## Web Spidering

This is the use of tools to help enumerate and map web applications. Numerous tools exist and some include: Burp Suite, WebScarab, Zed Attack Proxy (ZAP), and CAT.

These tools will parse through the HTML, find forms, and trying different inputs with checking responses to potentially find vulnerabilities. They might looks for common directories that contain potentially vulnerable or sensitive pages.

These tools may also have their downfalls. Though easy to operate, these tools will miss much of what the application may have to offer. These are a couple of the things that the application will miss:

1. Unusual navigation mechanisms. These can include dynamically generated pages.
1. Links buried within compiled client-side objects such as flash or java applets.
1. There may be a multistage functionality within the application that will not accept values put in by an automated tool.
1. The same URL may be used by an application for a multiple of forms. This may be a downfall as the automated tool may fingerprint the URL as one form, and after being used, when a different form under the same URL is give, may not try any inputs. This means that a whole side of the application may not even be tested.
1. Some appications may generate unique URLs that the tool cannot differentiate from and thus run indefinitely as it handles the same form as a different one as it has a different URL.
1. The spider needs to have the ability to authenticate itself whereever needed. If a form needs a token of sorts to execute correctly, then it must have it preconfigured. There are a number of weird conditions and circumstances that can be done:
    1. The Spider may log itself out as it finds the POST/GET request in doing so terminating the session.
    1. If the spider submits invalid input into a sensitive function, the application may terminate the session for defensive reasons.
    1. The Application may use per-page tokens. The spider in nearly all circumstances will fail in this aspect.

## User-Directed Spiders

This is a little more sophisticated methods where the user runs through the website as normal and the traffic is sent through the spider/proxy. 

The tool then builds a map of the application and incorporates all URLs found from the user browsing the pages. Two of the two mentions as spiders earlier: Burp Suite and WebScarab have this ability. There are numerous benefits over normal spiders, these include when:

1. The application uses unique, complex, or unusual mechanisms for navigation.
1. The user controls all the data sent into the application making sure all input validation is met.
1. The user logs into the application normally, this ensures that the authentication process remains active throughout the mapping process.
1. Any dangerous functionality such as "deleteUser.jsp" is also mapped, but th user will choose not to run the function and thus it will not be executed.

## Discovering Hidden Content

This is content that is not directly linked or reachable from the original content. This usually is content or code that was written for testing or debugging purposes. This is also common for applications with many levels of horizontal priveleges. This being the ones with anonymous, normal, and admin types roles.  

Thus the spidering approach may not find the content that is available at admin level while browsing at a normal level. To discover such content can be possible, but will need a certain degree of luck. 

A tool that may help with this process is to use a tool such as Nikto. It tries to find some common hidden paths and files.

### Brute Forcing Techniques

This is the act of making requests to directories within the site that may or may not exist. Thus, if a page is contacted, the response could be a 200. This would suggest that page exists. But more likely it will come back with a 404 response. There is another chance that it may be 403 or 302, which means that the page exists and the user trying to access it isn't allowed.

The book recommends to use Burp Suite's Intruder. But there are better ways. A common one is to use OWASP's DirBuster, found on GitHub, then pipe the output into httprobe, also found on GitHub.

### Inference from Public Content

Try to find patterns in the naming convention of resources. If an application is using a certain naming scheme, then try to make a wordlist that follows it.

### Use of Public Information

There are resources out there that are rather simple to use to gather more information than certain tools can get. These include:

1. Search Engines:
    - Google, MSN, and Yahoo have many spiders that are consistantly crawling through the internet and indexing information that may have not wanted to be indexed.
    - A good example of this being used is Google Dorking
        - site:www.example.com returns every resource within the target site that Google has a reference to.
        - site:www.example.com login returns all the pages containing the expression login. In a large and complex application, this technique can be used to quickly home in on interesting resources, such as site maps, password reset functions, and administrative menus.
        - link:www.example.com returns all the pages on other websites and applications that contain a link to the target. This may include links to old content, or functionality that is intended for use only by third par- ties, such as partner links.
        - related:www.example.com returns pages that are “similar” to the target and therefore includes a lot of irrelevant material. However, it may also discuss the target on other sites, which may be of interest.
1. Web Archives:
    - Such as the WayBack Machine can be used to who sites from a preselected time in the past.
    - Also one thing to note is that the site may talk of a relation to how it interacts with a third party. This in turn can lead you to the third party's site which could explain technological aspects of the first company that wasn't on the first party's own site.

### Leveraging the Web Server

The web server itself may be vulnerable to specific types of attacks that could list out the contents of a directory or the like. This is rather traditional pentesting in nature.

## Discovering Hidden Parameters

There may be hidden parameters that can alter how the application runs. An example for this may be when adding: ```debug=true```. The application may allow for some data, or even show more.

## Analyzing the Application

This is the act of enumerating as much as possible. Some key areas within this are:

- The Application's core functionality (the actions that can be leveraged to perform when used as intended)
- Other, more peripheral application behavior, including off-site links, error messages, admin and logging functions, and the use of redirects.
- Core security mechanisms and how they function. Thus, how is session state managed, access controls, auth mechanisms, and supporting logic (user reg, password updating, and account recovery.)
- The different locations at which the application processes user-supplied input
- The tech employed on the client side (forms, scripts, thick-clients, and cookies)
- Any details that may be gleaned about the internal structure and functionality of the server side component.

## Identifying Entry Points for User Input

Common entry points include:
- Every URL string up to the query string marker
- Every parameter submitted within the URL query string
- Every parameter submitted within the body of a POST request
- Every cookie
- Every other HTTP header that the application might process (user-agent, referer, accept, accept-language, and host)

### URL File Paths

The parts of the URL the precede the query string are usually overlooked as entry points, since they may seem as names of directories. In the case of REST-style URLs, this is different as they act as parameters. For example:

    http://example.com/shop/browse/electronics/iphone/

The strings "electronics" and "iphone" should be treated as parameters.

### Request Parameters

Parameters that are submitted within the URL string, message body, and HTTP Cookies are the most obvious. In this respect, one should note how the parameters are done. Most likely, they are formatted as name=value, but this may not always be the case. Here are some examples of nonstandard parameter formats

    /dir/file;foo=bar&foo2=bar2
    /dir/file?foo=bar$foo2=bar2
    /dir/file/foo%3dbar%26foo2%3dbar2
    /dir/foo.bar/file
    /dir/foo=bar/file
    /dir/file?param=foo:bar
    /dir/file?data=%3cfoo%3ebar%3c%2ffoo%3e%3cfoo2%3ebar2%3c%2ffoo2%3e

Thus take the format for parameters into account when probing for vulns. 

### HTTP Headers

Some applications may have custom logging functions and may log the contents of Referer and User-Agent. Thus they should be considered possible points of entry.

Some applications perform additional processing on the referer header. So, the site may detect that the user has arrived via a search engine. Then it may try to tailor the experience and make a customized response to the user's search query. The App may even echo the search term.

Some sites may even try to boost their search rankings by dynamically adding content such as HTML keywords which contain strings that recent visitors from search engines have been searching for. This means that is may be possible to inject content into the app's responses by making numerous requests containing suitably crafted Referer URL.

As for the User-Agent header, different devices may get different code when requesting resources as one may be mobile, while the other desktop related. This means that there may be an attack surface that can be uncovered via changing the user-agent string.

Lastly, sites may perform different actions on IP addresses. They may get the IP addresses in 2 ways. The first being through various APIs. The second being through the X-Forwarded-For header. Thus they may not check if the header was changed and could lead to SQL injection attacks and persistant cross-site scripting.

### Out-of-Band Channels

The last class of entry points for user input includes out-of-band channels by which the app recieves data that you may be able control. These may be undetectable as they aren't really seen in the traffic. Here are some examples:

- A web mail app that processes and renders e-mail msgs recieved via SMTP
- An app that contains a function to retrive content via HTTP from another server
- An intrusion detection application that gathers data using a network sniffer and presents this using a web app interface.
- Any kind of app that provides an API interface for use by non-browser user agents, such as cell phone apps.

## Identifying Server-Side Technology

This is the process of finger printing what the tech that is used by the server.

### Banner Grabbing

Many servers disclose fine-grained version info. For example with this example server header

    Server: Apache/1.3.31 (Unix) mod_gzip/1.3.26.1a mod_auth_passthrough/ 
    1.8 mod_log_bytes/1.2 mod_bwlimited/1.4 PHP/4.3.9 FrontPage/ 
    5.0.2.2634a mod_ssl/2.8.20 OpenSSL/0.9.7a

But the server info may not be shown just in the Server header, it may also be in:

- Templates used to build HTML pages
- Custom HTTP Headers
- URL query string parameters

### HTTP Fingerprinting

The Server header may not always be a reliable way in fingerprinting. Becuase of this, there are many other ways of finding out what technologies are used by the server. One of them is the tool: "Httprecon" which performs a number of tests in an attempt to fingerprint the web server.

### File Extentions

Here are common file extentions that aid in fingerprinting languages used by the server:

- asp — Microsoft Active Server Pages
- aspx — Microsoft ASP.NET
- jsp — Java Server Pages n cfm — Cold Fusion
- php — The PHP language n d2w — WebSphere
- pl — The Perl language
- py — The Python language
- dll — Usually compiled native code (C or C++)
- nsf or ntf — Lotus Domino

If there aren't extentions, there is still another way. For instance: if a user requests a nonexistent .aspx file, the server returns a custom error page generated by the ASP.NET framework

### Directory Names

Common subdirectory names can indicate a certain technology:

- servlet           - Java servlets
- pls               - Oracle Application Server PL/SQL gateway
- cfdocs or cfide   - Cold Fusion
- SilverStream      -the SilverStream web server
- WebObjects or {function}.woa - Apple WebObjects
- rails             - Ruby on Rails

### Session Tokens

As with the directory names above, there are common session token names:

- JSESSIONID        - The Java Platform
- ASPSESSIONID      - Microsoft IIS server
- ASP.NET_SessionID - Microsft ASP.NET
- CFID/CFTOKEN      - Cold Fusion
- PHPSession        - PHP

## Identifying Server-Side Functionality

It is often possible to infer a great deal about server-side functionality and struc- ture, or at least make an educated guess, by observing clues that the application discloses to the client.

### Dissecting Requests

#### Consider:

    https://wahh-app.com/calendar.jsp?name=new%20applicants&isExpired= 0&startDate=22%2F09%2F2010&endDate=22%2F03%2F2011&OrderBy=name

With this you can infer:

- The .jsp extention suggests a Java Server Page
- The OrderBy parameter suggests a back-end db (value submitted with the ```order by``` clause within SQL), thus it may be vulnerable to SQL injection
- Another interesting thing is the isExpired field. It's a boolean value that may specify whether the search query should include expired content. (Thus a possible access control vuln)

#### Another Example:

    https://wahh-app.com/workbench.aspx?template=NewBranch.tpl&loc= /default&ver=2.31&edit=false

- The .aspx suggests a ASP.NET app
- Template parameter used to specify filename
- ```loc``` parameter specify directory
- .tpl confirms above two
- These parameters may be vulnerable to dir traversal attacks. Also maybe allowing arbitrary files to be read from the server
- The ```edit``` parameter is set to false
    - Could be if changed: will modify the registration functionality.
    - Leads to possibility of editable items that weren't intended of being vuln.
- ```ver``` parameter does not have any readily guessable purpose, but changes to it may change the behavior of the app.

#### Final example:


    POST /feedback.php HTTP/1.1 
    Host: wahh-app.com 
    Content-Length: 389

    from=user@wahh-mail.com&to=helpdesk@wahh-app.com&subject= Problem+logging+in&message=Please+help...

- .php extention indicates PHP
- Likely to interface with external email system
- Appears that user-controlled input is being passed into the system in all relevent fields of the email
- Possible to exploit and send arbitrary messages to any recipient
- All fields may be open to header injection

### Extrapolating Application Behavior

Functionality around the site may be universal as it follows the same scheme, thus a certain vuln being vulnerable to other parts due to using the same filter. 

Another example is obfuscated data. If a developer uses this technique, there may be a part of the application that takes the error code and de-obfuscates the data. Then you may be able to take a cookie and put it into the error deobfuscator.

Errors are usually handled differently throughout the site. One part may handle it the right way, while another may handle it by crashing and returning verbose info to the user.

## Mapping the Attack Surface

The final stage of the mapping process is to identify the various attack surfaces exposed by the application and the potential vulns commonly associated with each one. Here are a couple:

- Client-side validation 
    - Checks may not be replicated by the server
- DB interaction 
    - SQL Injection
- File uploading/dowloading 
    - Path traversal vulns, stored XSS
- Display of user-supplied data 
    - XSS
- Dynamic redirects 
    - redirection and header injection attacks
- Social networking features 
    - username enumeration, stored XSS
- Login 
    - username enumeration, brute force
- Multistage login 
    - Logic flaws
- Session state 
    - Predictable tokens, insecure handling of tokens
- Access Controls
    - Horizontal/Vertical priv escalation
- User impersonation functions
    - Priv escalation
- Use of cleartext comms
    - Session hijacking, capture of creds
- Off-site links
    - Leakage of query string parameters in the ```Referer``` header
- Interfaces of external systems
    - Shortcuts in handling of sessions and/or access controls
- Error messages
    - Information leakage
- E-mail interaction
    - E-mail and/or command injection
- Native code components or interaction
    - Buffer overflows
- Use of 3rd party app components
    - Known vulnerabilities
- Identifiable web server software
    - Common config weaknesses / known bugs

